{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "s7o8rm-6_FUC",
        "bkhXDFFDBiXH",
        "sqCkrPgEzWiY",
        "PlQ4q70W47iO",
        "Wyxi_F0I4-IO",
        "u8AxB368B8yA",
        "W0U2Z1A65OVa"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parte II - Machine Learning Baseline"
      ],
      "metadata": {
        "id": "f8pQeVB9MyWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consigna"
      ],
      "metadata": {
        "id": "15iUNHve_HdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a construir un modelo muy sencillo para saber qué es lo peor que podemos hacer, en general esta es una tarea muy importante que queremos que repitan en sus proyectos de machine learning. ¿Por qué?\n",
        "\n",
        "* Navaja de Ockam: “Cuando se ofrecen dos o más explicaciones de un fenómeno, es preferible la explicación completa más simple; es decir, no deben multiplicarse las entidades sin necesidad.” ¿Para qué desarrollar un modelo super complejo si capaz es peor o casi igual que uno muy sencillo?\n",
        "* Nos sirve para saber si estamos usando bien los modelos más complejos, si su score nos da peor al baseline probablemente se deba a un error de código.\n",
        "* Nos sirve para rápidamente saber que tan complejo es un problema.\n",
        "* Los modelos simples son fáciles de entender.\n",
        "\n",
        "Utilice **todas las columnas del dataset** (exceptuando columnas que no tenga sentido usar para predecir) con algún encoding donde sea necesario para entrenar una regresión logística, utilizando búsqueda de hiperparametros y garantizando la reproducibilidad de los resultados cuando el notebook corriera varias veces. Conteste las preguntas:\n",
        "\n",
        "* ¿Cuál es el mejor score de validación obtenido? (¿Cómo conviene obtener el dataset para validar?)\n",
        "* Al predecir con este modelo para test, ¿Cúal es el score obtenido? (guardar el csv con predicciones para entregarlo después)\n",
        "* ¿Qué features son los más importantes para predecir con el mejor modelo? Graficar."
      ],
      "metadata": {
        "id": "RhDD34aK_Iys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "s7o8rm-6_FUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-MSHdP5KCv4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis del dataset y división de train y test"
      ],
      "metadata": {
        "id": "bkhXDFFDBiXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet('/content/drive/MyDrive/Datos/TP3/train')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x67OL4LmM1Pz",
        "outputId": "e2d127dc-5d87-4f3d-8a79-8820a1f7fcae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     url  timedelta  \\\n",
              "0      http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
              "1      http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
              "2      http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
              "3      http://mashable.com/2013/01/07/astronaut-notre...      731.0   \n",
              "4       http://mashable.com/2013/01/07/att-u-verse-apps/      731.0   \n",
              "...                                                  ...        ...   \n",
              "35658  http://mashable.com/2014/10/28/cree-led-light-...       72.0   \n",
              "35659  http://mashable.com/2014/10/28/dancing-with-th...       72.0   \n",
              "35660  http://mashable.com/2014/10/28/dangerous-airpo...       72.0   \n",
              "35661  http://mashable.com/2014/10/28/disney-villains...       72.0   \n",
              "35662  http://mashable.com/2014/10/28/doctor-who-mons...       72.0   \n",
              "\n",
              "       n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
              "0                12.0             219.0         0.663594               1.0   \n",
              "1                 9.0             255.0         0.604743               1.0   \n",
              "2                 9.0             211.0         0.575130               1.0   \n",
              "3                 9.0             531.0         0.503788               1.0   \n",
              "4                13.0            1072.0         0.415646               1.0   \n",
              "...               ...               ...              ...               ...   \n",
              "35658            12.0             323.0         0.573668               1.0   \n",
              "35659            13.0             433.0         0.563084               1.0   \n",
              "35660            13.0            1061.0         0.498020               1.0   \n",
              "35661            13.0            1777.0         0.449708               1.0   \n",
              "35662            10.0             540.0         0.500938               1.0   \n",
              "\n",
              "       n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
              "0                      0.815385        4.0             2.0       1.0  ...   \n",
              "1                      0.791946        3.0             1.0       1.0  ...   \n",
              "2                      0.663866        3.0             1.0       1.0  ...   \n",
              "3                      0.665635        9.0             0.0       1.0  ...   \n",
              "4                      0.540890       19.0            19.0      20.0  ...   \n",
              "...                         ...        ...             ...       ...  ...   \n",
              "35658                  0.729282        4.0             1.0       0.0  ...   \n",
              "35659                  0.756654        3.0             2.0       9.0  ...   \n",
              "35660                  0.686688        5.0             5.0       1.0  ...   \n",
              "35661                  0.631970       36.0            28.0      12.0  ...   \n",
              "35662                  0.674194        3.0             3.0       2.0  ...   \n",
              "\n",
              "       max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
              "0                  -0.200000            0.500000                 -0.187500   \n",
              "1                  -0.100000            0.000000                  0.000000   \n",
              "2                  -0.133333            0.000000                  0.000000   \n",
              "3                  -0.166667            0.000000                  0.000000   \n",
              "4                  -0.050000            0.454545                  0.136364   \n",
              "...                      ...                 ...                       ...   \n",
              "35658              -0.155556            0.288889                 -0.155556   \n",
              "35659              -0.166667            0.833333                  0.500000   \n",
              "35660              -0.050000            0.400000                 -0.400000   \n",
              "35661              -0.100000            0.000000                  0.000000   \n",
              "35662              -0.050000            0.166667                  0.125000   \n",
              "\n",
              "       abs_title_subjectivity  abs_title_sentiment_polarity  \\\n",
              "0                    0.000000                      0.187500   \n",
              "1                    0.500000                      0.000000   \n",
              "2                    0.500000                      0.000000   \n",
              "3                    0.500000                      0.000000   \n",
              "4                    0.045455                      0.136364   \n",
              "...                       ...                           ...   \n",
              "35658                0.211111                      0.155556   \n",
              "35659                0.333333                      0.500000   \n",
              "35660                0.100000                      0.400000   \n",
              "35661                0.500000                      0.000000   \n",
              "35662                0.333333                      0.125000   \n",
              "\n",
              "                                                 content     surprise1  \\\n",
              "0      \\nHaving trouble finding something to watch on...     the world   \n",
              "1      \\nThe Associated Press is the latest news orga...      business   \n",
              "2      \\nIt looks like 2012 was a pretty good year fo...     the world   \n",
              "3      \\nWhen it comes to college football, NASA astr...        sports   \n",
              "4      \\nLAS VEGAS -- Sharing photos and videos on yo...     the world   \n",
              "...                                                  ...           ...   \n",
              "35658  \\nLED lighting is more power-efficient and las...  science/tech   \n",
              "35659  \\nWith only eight couples left, ABC had to fin...     the world   \n",
              "35660  \\nParo Airport in Bhutan is located in a deep ...     the world   \n",
              "35661  \\nDisney villains are evil, but no one tops th...     the world   \n",
              "35662  \\nDoctor Who's monstersIn its early days, 'Doc...  science/tech   \n",
              "\n",
              "               surprise2  popular  shares  \n",
              "0      amusement,disgust    False     593  \n",
              "1                           False     711  \n",
              "2                           False    1500  \n",
              "3                           False    1200  \n",
              "4                           False     505  \n",
              "...                  ...      ...     ...  \n",
              "35658                        True   42000  \n",
              "35659                       False    2300  \n",
              "35660   disgust,optimism    False     567  \n",
              "35661      love,optimism    False     783  \n",
              "35662                       False    1400  \n",
              "\n",
              "[35663 rows x 65 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73eb0389-b897-438b-8e4a-85895d1fadcf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>timedelta</th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>...</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "      <th>abs_title_subjectivity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "      <th>content</th>\n",
              "      <th>surprise1</th>\n",
              "      <th>surprise2</th>\n",
              "      <th>popular</th>\n",
              "      <th>shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>0.663594</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.815385</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>\\nHaving trouble finding something to watch on...</td>\n",
              "      <td>the world</td>\n",
              "      <td>amusement,disgust</td>\n",
              "      <td>False</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.604743</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.791946</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nThe Associated Press is the latest news orga...</td>\n",
              "      <td>business</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>0.575130</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.663866</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nIt looks like 2012 was a pretty good year fo...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>0.503788</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.665635</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nWhen it comes to college football, NASA astr...</td>\n",
              "      <td>sports</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
              "      <td>731.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1072.0</td>\n",
              "      <td>0.415646</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.540890</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>\\nLAS VEGAS -- Sharing photos and videos on yo...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35658</th>\n",
              "      <td>http://mashable.com/2014/10/28/cree-led-light-...</td>\n",
              "      <td>72.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>323.0</td>\n",
              "      <td>0.573668</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.729282</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.155556</td>\n",
              "      <td>0.288889</td>\n",
              "      <td>-0.155556</td>\n",
              "      <td>0.211111</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>\\nLED lighting is more power-efficient and las...</td>\n",
              "      <td>science/tech</td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "      <td>42000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35659</th>\n",
              "      <td>http://mashable.com/2014/10/28/dancing-with-th...</td>\n",
              "      <td>72.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>433.0</td>\n",
              "      <td>0.563084</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.756654</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>\\nWith only eight couples left, ABC had to fin...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>2300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35660</th>\n",
              "      <td>http://mashable.com/2014/10/28/dangerous-airpo...</td>\n",
              "      <td>72.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1061.0</td>\n",
              "      <td>0.498020</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.686688</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>\\nParo Airport in Bhutan is located in a deep ...</td>\n",
              "      <td>the world</td>\n",
              "      <td>disgust,optimism</td>\n",
              "      <td>False</td>\n",
              "      <td>567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35661</th>\n",
              "      <td>http://mashable.com/2014/10/28/disney-villains...</td>\n",
              "      <td>72.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1777.0</td>\n",
              "      <td>0.449708</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.631970</td>\n",
              "      <td>36.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nDisney villains are evil, but no one tops th...</td>\n",
              "      <td>the world</td>\n",
              "      <td>love,optimism</td>\n",
              "      <td>False</td>\n",
              "      <td>783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35662</th>\n",
              "      <td>http://mashable.com/2014/10/28/doctor-who-mons...</td>\n",
              "      <td>72.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>0.500938</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.674194</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>\\nDoctor Who's monstersIn its early days, 'Doc...</td>\n",
              "      <td>science/tech</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>1400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35663 rows × 65 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73eb0389-b897-438b-8e4a-85895d1fadcf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73eb0389-b897-438b-8e4a-85895d1fadcf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73eb0389-b897-438b-8e4a-85895d1fadcf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ5aNhQUNMH0",
        "outputId": "a8458c2c-eaf8-42a8-9f80-55d298c31c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['url', 'timedelta', 'n_tokens_title', 'n_tokens_content',\n",
              "       'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens',\n",
              "       'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos',\n",
              "       'average_token_length', 'num_keywords', 'data_channel_is_lifestyle',\n",
              "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
              "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
              "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
              "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
              "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
              "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
              "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
              "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
              "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
              "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
              "       'global_rate_negative_words', 'rate_positive_words',\n",
              "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
              "       'max_positive_polarity', 'avg_negative_polarity',\n",
              "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
              "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
              "       'abs_title_sentiment_polarity', 'content', 'surprise1', 'surprise2',\n",
              "       'popular', 'shares'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "8rg7QAxoQH5n",
        "outputId": "8e4154e6-c8fa-44a4-aa70-85fcd5a4bed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35663 entries, 0 to 35662\n",
            "Data columns (total 65 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   url                            35663 non-null  object \n",
            " 1   timedelta                      35663 non-null  float64\n",
            " 2   n_tokens_title                 35662 non-null  float64\n",
            " 3   n_tokens_content               35661 non-null  float64\n",
            " 4   n_unique_tokens                35662 non-null  float64\n",
            " 5   n_non_stop_words               35662 non-null  float64\n",
            " 6   n_non_stop_unique_tokens       35661 non-null  float64\n",
            " 7   num_hrefs                      35660 non-null  float64\n",
            " 8   num_self_hrefs                 35661 non-null  float64\n",
            " 9   num_imgs                       35660 non-null  float64\n",
            " 10  num_videos                     35657 non-null  float64\n",
            " 11  average_token_length           35663 non-null  float64\n",
            " 12  num_keywords                   35662 non-null  float64\n",
            " 13  data_channel_is_lifestyle      35663 non-null  float64\n",
            " 14  data_channel_is_entertainment  35663 non-null  float64\n",
            " 15  data_channel_is_bus            35662 non-null  float64\n",
            " 16  data_channel_is_socmed         35661 non-null  float64\n",
            " 17  data_channel_is_tech           35662 non-null  float64\n",
            " 18  data_channel_is_world          35663 non-null  float64\n",
            " 19  kw_min_min                     35661 non-null  float64\n",
            " 20  kw_max_min                     35662 non-null  float64\n",
            " 21  kw_avg_min                     35662 non-null  float64\n",
            " 22  kw_min_max                     35662 non-null  float64\n",
            " 23  kw_max_max                     35661 non-null  float64\n",
            " 24  kw_avg_max                     35663 non-null  float64\n",
            " 25  kw_min_avg                     35662 non-null  float64\n",
            " 26  kw_max_avg                     35663 non-null  float64\n",
            " 27  kw_avg_avg                     35663 non-null  float64\n",
            " 28  self_reference_min_shares      35663 non-null  float64\n",
            " 29  self_reference_max_shares      35663 non-null  float64\n",
            " 30  self_reference_avg_sharess     35661 non-null  float64\n",
            " 31  weekday_is_monday              35659 non-null  float64\n",
            " 32  weekday_is_tuesday             35660 non-null  float64\n",
            " 33  weekday_is_wednesday           35661 non-null  float64\n",
            " 34  weekday_is_thursday            35663 non-null  float64\n",
            " 35  weekday_is_friday              35661 non-null  float64\n",
            " 36  weekday_is_saturday            35662 non-null  float64\n",
            " 37  weekday_is_sunday              35663 non-null  float64\n",
            " 38  is_weekend                     35663 non-null  float64\n",
            " 39  LDA_00                         35660 non-null  float64\n",
            " 40  LDA_01                         35661 non-null  float64\n",
            " 41  LDA_02                         35661 non-null  float64\n",
            " 42  LDA_03                         35660 non-null  float64\n",
            " 43  LDA_04                         35663 non-null  float64\n",
            " 44  global_subjectivity            35663 non-null  float64\n",
            " 45  global_sentiment_polarity      35662 non-null  float64\n",
            " 46  global_rate_positive_words     35662 non-null  float64\n",
            " 47  global_rate_negative_words     35661 non-null  float64\n",
            " 48  rate_positive_words            35662 non-null  float64\n",
            " 49  rate_negative_words            35662 non-null  float64\n",
            " 50  avg_positive_polarity          35662 non-null  float64\n",
            " 51  min_positive_polarity          35663 non-null  float64\n",
            " 52  max_positive_polarity          35659 non-null  float64\n",
            " 53  avg_negative_polarity          35662 non-null  float64\n",
            " 54  min_negative_polarity          35662 non-null  float64\n",
            " 55  max_negative_polarity          35661 non-null  float64\n",
            " 56  title_subjectivity             35661 non-null  float64\n",
            " 57  title_sentiment_polarity       35663 non-null  float64\n",
            " 58  abs_title_subjectivity         35661 non-null  float64\n",
            " 59  abs_title_sentiment_polarity   35662 non-null  float64\n",
            " 60  content                        35661 non-null  object \n",
            " 61  surprise1                      35663 non-null  object \n",
            " 62  surprise2                      35663 non-null  object \n",
            " 63  popular                        35663 non-null  bool   \n",
            " 64  shares                         35663 non-null  int64  \n",
            "dtypes: bool(1), float64(59), int64(1), object(4)\n",
            "memory usage: 17.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['surprise1'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KO-7ysUkxh_",
        "outputId": "81087070-4b2a-4d08-8c73-6d0c337d66db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count         35663\n",
              "unique            4\n",
              "top       the world\n",
              "freq          24893\n",
              "Name: surprise1, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['surprise2'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0Z0UTL-k1fd",
        "outputId": "f7f8a12c-0479-4002-8837-28f8f1b0e1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     35663\n",
              "unique       75\n",
              "top            \n",
              "freq      21837\n",
              "Name: surprise2, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separo el target del resto del dataset:"
      ],
      "metadata": {
        "id": "ZS0rmWfCQCN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:,:-2]\n",
        "y = df.popular"
      ],
      "metadata": {
        "id": "iA659CQJPg0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tomo el 90% de las filas para entrenar y el otro 10% para validar. Para evitar el time-travelling y como los datos estan ordenados segun timedelta, tomo los primeros registros para entrenar y los restantes para validar, en lugar de tomar registros random:"
      ],
      "metadata": {
        "id": "896qdlGw87JO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = x.head(int(len(x)*0.9)).copy(), y.head(int(len(y)*0.9)).copy()\n",
        "x_valid, y_valid = x.tail(int(len(x)*0.1)).copy(), y.tail(int(len(y)*0.1)).copy()"
      ],
      "metadata": {
        "id": "RDSSERdLPh1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.head(6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "RNvG6mkWPibh",
        "outputId": "7f01f97f-659d-454c-d7a2-bfe208f1cfdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 url  timedelta  \\\n",
              "0  http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
              "1  http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
              "2  http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
              "3  http://mashable.com/2013/01/07/astronaut-notre...      731.0   \n",
              "4   http://mashable.com/2013/01/07/att-u-verse-apps/      731.0   \n",
              "5   http://mashable.com/2013/01/07/beewi-smart-toys/      731.0   \n",
              "\n",
              "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
              "0            12.0             219.0         0.663594               1.0   \n",
              "1             9.0             255.0         0.604743               1.0   \n",
              "2             9.0             211.0         0.575130               1.0   \n",
              "3             9.0             531.0         0.503788               1.0   \n",
              "4            13.0            1072.0         0.415646               1.0   \n",
              "5            10.0             370.0         0.559889               1.0   \n",
              "\n",
              "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
              "0                  0.815385        4.0             2.0       1.0  ...   \n",
              "1                  0.791946        3.0             1.0       1.0  ...   \n",
              "2                  0.663866        3.0             1.0       1.0  ...   \n",
              "3                  0.665635        9.0             0.0       1.0  ...   \n",
              "4                  0.540890       19.0            19.0      20.0  ...   \n",
              "5                  0.698198        2.0             2.0       0.0  ...   \n",
              "\n",
              "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
              "0              -0.350000                 -0.600              -0.200000   \n",
              "1              -0.118750                 -0.125              -0.100000   \n",
              "2              -0.466667                 -0.800              -0.133333   \n",
              "3              -0.369697                 -0.600              -0.166667   \n",
              "4              -0.220192                 -0.500              -0.050000   \n",
              "5              -0.195000                 -0.400              -0.100000   \n",
              "\n",
              "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
              "0            0.500000                 -0.187500                0.000000   \n",
              "1            0.000000                  0.000000                0.500000   \n",
              "2            0.000000                  0.000000                0.500000   \n",
              "3            0.000000                  0.000000                0.500000   \n",
              "4            0.454545                  0.136364                0.045455   \n",
              "5            0.642857                  0.214286                0.142857   \n",
              "\n",
              "   abs_title_sentiment_polarity  \\\n",
              "0                      0.187500   \n",
              "1                      0.000000   \n",
              "2                      0.000000   \n",
              "3                      0.000000   \n",
              "4                      0.136364   \n",
              "5                      0.214286   \n",
              "\n",
              "                                             content     surprise1  \\\n",
              "0  \\nHaving trouble finding something to watch on...     the world   \n",
              "1  \\nThe Associated Press is the latest news orga...      business   \n",
              "2  \\nIt looks like 2012 was a pretty good year fo...     the world   \n",
              "3  \\nWhen it comes to college football, NASA astr...        sports   \n",
              "4  \\nLAS VEGAS -- Sharing photos and videos on yo...     the world   \n",
              "5  \\nLAS VEGAS -- RC toys have traded in their bu...  science/tech   \n",
              "\n",
              "           surprise2  \n",
              "0  amusement,disgust  \n",
              "1                     \n",
              "2                     \n",
              "3                     \n",
              "4                     \n",
              "5                     \n",
              "\n",
              "[6 rows x 63 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1d0409e-9d72-42d4-9186-4b8015a15ad7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>timedelta</th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>...</th>\n",
              "      <th>avg_negative_polarity</th>\n",
              "      <th>min_negative_polarity</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "      <th>abs_title_subjectivity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "      <th>content</th>\n",
              "      <th>surprise1</th>\n",
              "      <th>surprise2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>0.663594</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.815385</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.350000</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>\\nHaving trouble finding something to watch on...</td>\n",
              "      <td>the world</td>\n",
              "      <td>amusement,disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.604743</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.791946</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118750</td>\n",
              "      <td>-0.125</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nThe Associated Press is the latest news orga...</td>\n",
              "      <td>business</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>0.575130</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.663866</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.466667</td>\n",
              "      <td>-0.800</td>\n",
              "      <td>-0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nIt looks like 2012 was a pretty good year fo...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>0.503788</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.665635</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.369697</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nWhen it comes to college football, NASA astr...</td>\n",
              "      <td>sports</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
              "      <td>731.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1072.0</td>\n",
              "      <td>0.415646</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.540890</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.220192</td>\n",
              "      <td>-0.500</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>\\nLAS VEGAS -- Sharing photos and videos on yo...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>http://mashable.com/2013/01/07/beewi-smart-toys/</td>\n",
              "      <td>731.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>370.0</td>\n",
              "      <td>0.559889</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.698198</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.195000</td>\n",
              "      <td>-0.400</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>\\nLAS VEGAS -- RC toys have traded in their bu...</td>\n",
              "      <td>science/tech</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 63 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1d0409e-9d72-42d4-9186-4b8015a15ad7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1d0409e-9d72-42d4-9186-4b8015a15ad7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1d0409e-9d72-42d4-9186-4b8015a15ad7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding"
      ],
      "metadata": {
        "id": "sqCkrPgEzWiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comienzo quitando las columnas timedelta y url del dataset ya que no las voy a usar para predecir:"
      ],
      "metadata": {
        "id": "i-lQYNqJi1aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.iloc[:,2:]\n",
        "x_valid = x_valid.iloc[:,2:]"
      ],
      "metadata": {
        "id": "tmAcOc0gi1Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para los valores numéricos del dataset reemplazo los nans con la media de la columna:"
      ],
      "metadata": {
        "id": "Unf_EEeshkvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "means = {}\n",
        "\n",
        "def fill_numeric_na(data):\n",
        "  for column in data:\n",
        "    if data[column].dtype == np.float64:\n",
        "      if column not in means:\n",
        "        mean =  data[column].sum()/len(data[column])\n",
        "        means[column] = mean\n",
        "      data[column].fillna(means[column], inplace=True)\n",
        "  \n",
        "fill_numeric_na(x_train)\n",
        "fill_numeric_na(x_valid)"
      ],
      "metadata": {
        "id": "it1G_Vz536FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como este modelo es un baseline encodeo el contenido de manera simple reemplazando con la longitud del string:"
      ],
      "metadata": {
        "id": "c2adZ5-uh-N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_content(data):\n",
        "  data['content_len'] = data['content'].map(lambda x: len(x) if x else 0)\n",
        "  data.drop('content', axis=1, inplace=True)\n",
        "\n",
        "transform_content(x_train)\n",
        "transform_content(x_valid)"
      ],
      "metadata": {
        "id": "YAF95YSv7aD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el caso de surprise1 y surprise2, para no complejzar el modelo baseline aplico One Hot Encoding a ambos:"
      ],
      "metadata": {
        "id": "GxCjkgzoiLu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "surprise1_encoder = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
        "encoded_sur1 = surprise1_encoder.fit_transform(x_train[['surprise1']]).todense().astype(int)\n",
        "x_train = x_train.reset_index().drop(['index', 'surprise1'], axis=1).join(pd.DataFrame(encoded_sur1, columns=surprise1_encoder.get_feature_names_out()))\n",
        "encoded_sur1 = surprise1_encoder.transform(x_valid[['surprise1']]).todense().astype(int)\n",
        "x_valid = x_valid.reset_index().drop(['index', 'surprise1'], axis=1).join(pd.DataFrame(encoded_sur1, columns=surprise1_encoder.get_feature_names_out()))\n",
        "\n",
        "surprise2_encoder = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
        "encoded_sur2 = surprise2_encoder.fit_transform(x_train[['surprise2']]).todense().astype(int)\n",
        "x_train = x_train.reset_index().drop(['index', 'surprise2'], axis=1).join(pd.DataFrame(encoded_sur2, columns=surprise2_encoder.get_feature_names_out()))\n",
        "encoded_sur2 = surprise2_encoder.transform(x_valid[['surprise2']]).todense().astype(int)\n",
        "x_valid = x_valid.reset_index().drop(['index', 'surprise2'], axis=1).join(pd.DataFrame(encoded_sur2, columns=surprise2_encoder.get_feature_names_out()))"
      ],
      "metadata": {
        "id": "5uzBNAw6_G_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid.head(6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "TYOiyYjIkj6N",
        "outputId": "dd00f8ef-3a8d-4a88-b648-350cd258f1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
              "0            10.0             458.0         0.544218               1.0   \n",
              "1             6.0             713.0         0.466761               1.0   \n",
              "2            13.0            1341.0         0.457207               1.0   \n",
              "3             7.0             731.0         0.455307               1.0   \n",
              "4            15.0             610.0         0.494983               1.0   \n",
              "5            11.0            1740.0         0.453875               1.0   \n",
              "\n",
              "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
              "0                  0.712687       11.0             0.0       0.0         2.0   \n",
              "1                  0.635036       11.0             0.0       1.0         0.0   \n",
              "2                  0.671815        1.0             1.0       3.0         2.0   \n",
              "3                  0.639225       11.0             3.0       1.0         0.0   \n",
              "4                  0.647383       16.0             5.0       1.0         0.0   \n",
              "5                  0.595427       10.0             8.0      52.0         0.0   \n",
              "\n",
              "   average_token_length  ...  surprise2_love,nervousness  \\\n",
              "0              4.764192  ...                           0   \n",
              "1              5.288920  ...                           0   \n",
              "2              4.501864  ...                           0   \n",
              "3              4.604651  ...                           0   \n",
              "4              4.804918  ...                           0   \n",
              "5              4.618966  ...                           0   \n",
              "\n",
              "   surprise2_love,optimism  surprise2_love,relief  surprise2_love,sadness  \\\n",
              "0                        0                      0                       0   \n",
              "1                        0                      0                       0   \n",
              "2                        0                      0                       0   \n",
              "3                        0                      0                       0   \n",
              "4                        0                      0                       0   \n",
              "5                        0                      0                       0   \n",
              "\n",
              "   surprise2_nervousness,optimism  surprise2_nervousness,sadness  \\\n",
              "0                               0                              0   \n",
              "1                               0                              0   \n",
              "2                               0                              0   \n",
              "3                               0                              0   \n",
              "4                               0                              0   \n",
              "5                               0                              0   \n",
              "\n",
              "   surprise2_neutral,optimism  surprise2_neutral,relief  \\\n",
              "0                           0                         0   \n",
              "1                           0                         0   \n",
              "2                           0                         0   \n",
              "3                           0                         0   \n",
              "4                           0                         0   \n",
              "5                           0                         0   \n",
              "\n",
              "   surprise2_optimism,relief  surprise2_optimism,sadness  \n",
              "0                          0                           0  \n",
              "1                          0                           0  \n",
              "2                          0                           0  \n",
              "3                          0                           0  \n",
              "4                          0                           0  \n",
              "5                          0                           0  \n",
              "\n",
              "[6 rows x 136 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be7580d5-8f81-48fa-8eea-9beee10ab582\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>num_videos</th>\n",
              "      <th>average_token_length</th>\n",
              "      <th>...</th>\n",
              "      <th>surprise2_love,nervousness</th>\n",
              "      <th>surprise2_love,optimism</th>\n",
              "      <th>surprise2_love,relief</th>\n",
              "      <th>surprise2_love,sadness</th>\n",
              "      <th>surprise2_nervousness,optimism</th>\n",
              "      <th>surprise2_nervousness,sadness</th>\n",
              "      <th>surprise2_neutral,optimism</th>\n",
              "      <th>surprise2_neutral,relief</th>\n",
              "      <th>surprise2_optimism,relief</th>\n",
              "      <th>surprise2_optimism,sadness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.0</td>\n",
              "      <td>458.0</td>\n",
              "      <td>0.544218</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.712687</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.764192</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.0</td>\n",
              "      <td>713.0</td>\n",
              "      <td>0.466761</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.635036</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.288920</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.0</td>\n",
              "      <td>1341.0</td>\n",
              "      <td>0.457207</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.671815</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.501864</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.0</td>\n",
              "      <td>731.0</td>\n",
              "      <td>0.455307</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.639225</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.604651</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>0.494983</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.647383</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.804918</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11.0</td>\n",
              "      <td>1740.0</td>\n",
              "      <td>0.453875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.595427</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.618966</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 136 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be7580d5-8f81-48fa-8eea-9beee10ab582')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be7580d5-8f81-48fa-8eea-9beee10ab582 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be7580d5-8f81-48fa-8eea-9beee10ab582');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Búsqueda de hiperparámetros y entrenamiento del modelo"
      ],
      "metadata": {
        "id": "PlQ4q70W47iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression = LogisticRegression(random_state=123)\n",
        "hiper_params = {\n",
        "    'C': np.logspace(-4, 4, 600),\n",
        "    'max_iter': [60, 80, 100, 120, 140, 160, 180, 200],\n",
        "    'penalty': ['l2', 'l1', 'none'],\n",
        "    'solver': ['lbfgs', 'newton-cg']}\n",
        "model = RandomizedSearchCV(logistic_regression, hiper_params, n_iter=10, scoring='roc_auc', random_state=123)\n",
        "model.fit(x_train.values, y_train.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKL52lACRveH",
        "outputId": "506f489b-c966-4364-b531-be00eab10bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "10 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.54893928 0.65979051 0.54893928 0.54416197 0.54134016        nan\n",
            " 0.65039039 0.66512743 0.67628459        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(estimator=LogisticRegression(random_state=123),\n",
              "                   param_distributions={'C': array([1.00000000e-04, 1.03123013e-04, 1.06343558e-04, 1.09664681e-04,\n",
              "       1.13089523e-04, 1.16621323e-04, 1.20263422e-04, 1.24019264e-04,\n",
              "       1.27892401e-04, 1.31886497e-04, 1.36005329e-04, 1.40252793e-04,\n",
              "       1.44632906e-04, 1.49149810e-04, 1.53807778e-04, 1.58611214e-04,\n",
              "       1.63564663e-...\n",
              "       6.30472445e+03, 6.50162180e+03, 6.70466828e+03, 6.91405593e+03,\n",
              "       7.12998278e+03, 7.35265305e+03, 7.58227735e+03, 7.81907284e+03,\n",
              "       8.06326348e+03, 8.31508023e+03, 8.57476125e+03, 8.84255214e+03,\n",
              "       9.11870618e+03, 9.40348454e+03, 9.69715656e+03, 1.00000000e+04]),\n",
              "                                        'max_iter': [60, 80, 100, 120, 140, 160,\n",
              "                                                     180, 200],\n",
              "                                        'penalty': ['l2', 'l1', 'none'],\n",
              "                                        'solver': ['lbfgs', 'newton-cg']},\n",
              "                   random_state=123, scoring='roc_auc')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción para validation"
      ],
      "metadata": {
        "id": "Wyxi_F0I4-IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_preds = model.predict(x_valid.values)\n",
        "proba_preds = model.predict_proba(x_valid.values)[:, 1]"
      ],
      "metadata": {
        "id": "IoJ7Loa58Y2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_valid.values, binary_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-segPhWtBELs",
        "outputId": "92dcdcc2-a961-43e5-eadf-d1822e3f3f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.83      0.98      0.90      2942\n",
            "        True       0.46      0.07      0.13       624\n",
            "\n",
            "    accuracy                           0.82      3566\n",
            "   macro avg       0.65      0.53      0.51      3566\n",
            "weighted avg       0.77      0.82      0.77      3566\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_valid.values, proba_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8JHLMBjBwnR",
        "outputId": "91cb3d87-09fd-4c65-eef8-a21eb2abb0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7138039489968449"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El mejor score obtenido para validation fue 0.7138039489968449."
      ],
      "metadata": {
        "id": "gqwtkj1YBXeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción para test"
      ],
      "metadata": {
        "id": "u8AxB368B8yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_parquet('/content/drive/MyDrive/Datos/TP3/test')\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MIxBJq0gB_O9",
        "outputId": "e2dcd515-b6e2-4fb2-9958-0e3dcc3bced6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    url  timedelta  \\\n",
              "0     http://mashable.com/2014/10/28/dress-up-willow...       71.0   \n",
              "1     http://mashable.com/2014/10/28/dumb-ways-to-di...       71.0   \n",
              "2     http://mashable.com/2014/10/28/ebola-health-ca...       71.0   \n",
              "3     http://mashable.com/2014/10/28/ebola-patient-z...       71.0   \n",
              "4     http://mashable.com/2014/10/28/ebola-symptoms-...       71.0   \n",
              "...                                                 ...        ...   \n",
              "3976  http://mashable.com/2014/12/27/samsung-app-aut...        8.0   \n",
              "3977  http://mashable.com/2014/12/27/seth-rogen-jame...        8.0   \n",
              "3978  http://mashable.com/2014/12/27/son-pays-off-mo...        8.0   \n",
              "3979     http://mashable.com/2014/12/27/ukraine-blasts/        8.0   \n",
              "3980  http://mashable.com/2014/12/27/youtube-channel...        8.0   \n",
              "\n",
              "      n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
              "0               11.0             739.0         0.439944               1.0   \n",
              "1                9.0             199.0         0.663265               1.0   \n",
              "2               11.0             568.0         0.473310               1.0   \n",
              "3               13.0             373.0         0.513889               1.0   \n",
              "4               11.0             841.0         0.462759               1.0   \n",
              "...              ...               ...              ...               ...   \n",
              "3976            11.0             346.0         0.529052               1.0   \n",
              "3977            12.0             328.0         0.696296               1.0   \n",
              "3978            10.0             442.0         0.516355               1.0   \n",
              "3979             6.0             682.0         0.539493               1.0   \n",
              "3980            10.0             157.0         0.701987               1.0   \n",
              "\n",
              "      n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
              "0                     0.591017       11.0             6.0       1.0  ...   \n",
              "1                     0.811966        5.0             2.0       1.0  ...   \n",
              "2                     0.627273        6.0             1.0       1.0  ...   \n",
              "3                     0.600823        4.0             2.0       7.0  ...   \n",
              "4                     0.656627        9.0             0.0       2.0  ...   \n",
              "...                        ...        ...             ...       ...  ...   \n",
              "3976                  0.684783        9.0             7.0       1.0  ...   \n",
              "3977                  0.885057        9.0             7.0       3.0  ...   \n",
              "3978                  0.644128       24.0             1.0      12.0  ...   \n",
              "3979                  0.692661       10.0             1.0       1.0  ...   \n",
              "3980                  0.846154        1.0             1.0       0.0  ...   \n",
              "\n",
              "      max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
              "0                 -0.125000            0.500000                  0.000000   \n",
              "1                 -0.500000            0.427778                  0.200000   \n",
              "2                 -0.050000            0.166667                  0.000000   \n",
              "3                 -0.100000            1.000000                  0.000000   \n",
              "4                 -0.025000            1.000000                  0.000000   \n",
              "...                     ...                 ...                       ...   \n",
              "3976              -0.125000            0.100000                  0.000000   \n",
              "3977              -0.100000            0.300000                  1.000000   \n",
              "3978              -0.166667            0.454545                  0.136364   \n",
              "3979              -0.012500            0.000000                  0.000000   \n",
              "3980              -0.200000            0.333333                  0.250000   \n",
              "\n",
              "      abs_title_subjectivity  abs_title_sentiment_polarity  \\\n",
              "0                   0.000000                      0.000000   \n",
              "1                   0.072222                      0.200000   \n",
              "2                   0.333333                      0.000000   \n",
              "3                   0.500000                      0.000000   \n",
              "4                   0.500000                      0.000000   \n",
              "...                      ...                           ...   \n",
              "3976                0.400000                      0.000000   \n",
              "3977                0.200000                      1.000000   \n",
              "3978                0.045455                      0.136364   \n",
              "3979                0.500000                      0.000000   \n",
              "3980                0.166667                      0.250000   \n",
              "\n",
              "                                                content  surprise1  \\\n",
              "0     \\nA toddler named Willow Lee is outdoing us al...  the world   \n",
              "1     \\nMetro Trains in Melbourne is back at it agai...  the world   \n",
              "2     \\nMore than 5,000 additional health care worke...  the world   \n",
              "3     \\nIn the Guinean village where the current Wes...  the world   \n",
              "4     \\nFear of Ebola has put many on high alert and...  the world   \n",
              "...                                                 ...        ...   \n",
              "3976  \\nWhile some believe smartphones and tablets m...  the world   \n",
              "3977  \\nLOS ANGELES -- Call it their exit Interview....  the world   \n",
              "3978  \\nNothing says \"Merry Christmas\" like never ha...  the world   \n",
              "3979  \\nUkrainians were on high alert on Saturday af...  the world   \n",
              "3980  \\nWe collectively watch more than 6 billion ho...  the world   \n",
              "\n",
              "              surprise2  popular  shares  \n",
              "0     disgust,gratitude    False    1300  \n",
              "1              joy,love    False     845  \n",
              "2                          False    1200  \n",
              "3                          False    2100  \n",
              "4                           True    5400  \n",
              "...                 ...      ...     ...  \n",
              "3976           joy,love    False    1800  \n",
              "3977      love,optimism    False    1900  \n",
              "3978                       False    1900  \n",
              "3979                       False    1100  \n",
              "3980                       False    1300  \n",
              "\n",
              "[3981 rows x 65 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac759d32-9808-4a76-938e-09798735a1e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>timedelta</th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>...</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "      <th>abs_title_subjectivity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "      <th>content</th>\n",
              "      <th>surprise1</th>\n",
              "      <th>surprise2</th>\n",
              "      <th>popular</th>\n",
              "      <th>shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://mashable.com/2014/10/28/dress-up-willow...</td>\n",
              "      <td>71.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>739.0</td>\n",
              "      <td>0.439944</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.591017</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.125000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nA toddler named Willow Lee is outdoing us al...</td>\n",
              "      <td>the world</td>\n",
              "      <td>disgust,gratitude</td>\n",
              "      <td>False</td>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://mashable.com/2014/10/28/dumb-ways-to-di...</td>\n",
              "      <td>71.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>0.663265</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.811966</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.427778</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.072222</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>\\nMetro Trains in Melbourne is back at it agai...</td>\n",
              "      <td>the world</td>\n",
              "      <td>joy,love</td>\n",
              "      <td>False</td>\n",
              "      <td>845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://mashable.com/2014/10/28/ebola-health-ca...</td>\n",
              "      <td>71.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>568.0</td>\n",
              "      <td>0.473310</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.627273</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nMore than 5,000 additional health care worke...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://mashable.com/2014/10/28/ebola-patient-z...</td>\n",
              "      <td>71.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>373.0</td>\n",
              "      <td>0.513889</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.600823</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nIn the Guinean village where the current Wes...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>2100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://mashable.com/2014/10/28/ebola-symptoms-...</td>\n",
              "      <td>71.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>841.0</td>\n",
              "      <td>0.462759</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.656627</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nFear of Ebola has put many on high alert and...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "      <td>5400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3976</th>\n",
              "      <td>http://mashable.com/2014/12/27/samsung-app-aut...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>0.529052</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.684783</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.125000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nWhile some believe smartphones and tablets m...</td>\n",
              "      <td>the world</td>\n",
              "      <td>joy,love</td>\n",
              "      <td>False</td>\n",
              "      <td>1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3977</th>\n",
              "      <td>http://mashable.com/2014/12/27/seth-rogen-jame...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.885057</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>\\nLOS ANGELES -- Call it their exit Interview....</td>\n",
              "      <td>the world</td>\n",
              "      <td>love,optimism</td>\n",
              "      <td>False</td>\n",
              "      <td>1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3978</th>\n",
              "      <td>http://mashable.com/2014/12/27/son-pays-off-mo...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>0.516355</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.644128</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>\\nNothing says \"Merry Christmas\" like never ha...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3979</th>\n",
              "      <td>http://mashable.com/2014/12/27/ukraine-blasts/</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>682.0</td>\n",
              "      <td>0.539493</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.692661</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\\nUkrainians were on high alert on Saturday af...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>1100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3980</th>\n",
              "      <td>http://mashable.com/2014/12/27/youtube-channel...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.701987</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>\\nWe collectively watch more than 6 billion ho...</td>\n",
              "      <td>the world</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3981 rows × 65 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac759d32-9808-4a76-938e-09798735a1e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac759d32-9808-4a76-938e-09798735a1e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac759d32-9808-4a76-938e-09798735a1e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = df.iloc[:,:-2]\n",
        "y_test = df.popular"
      ],
      "metadata": {
        "id": "bHbq0902C_Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding:"
      ],
      "metadata": {
        "id": "igiSdnBZDbPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test.iloc[:,2:]"
      ],
      "metadata": {
        "id": "ht9kZZOmDM2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fill_numeric_na(x_test)\n",
        "transform_content(x_test)"
      ],
      "metadata": {
        "id": "NXBk6qFcDSvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sur1 = surprise1_encoder.transform(x_test[['surprise1']]).todense().astype(int)\n",
        "x_test = x_test.reset_index().drop(['index', 'surprise1'], axis=1).join(pd.DataFrame(encoded_sur1, columns=surprise1_encoder.get_feature_names_out()))\n",
        "\n",
        "encoded_sur2 = surprise2_encoder.transform(x_test[['surprise2']]).todense().astype(int)\n",
        "x_test = x_test.reset_index().drop(['index', 'surprise2'], axis=1).join(pd.DataFrame(encoded_sur2, columns=surprise2_encoder.get_feature_names_out()))"
      ],
      "metadata": {
        "id": "G-V6E6hPDcvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI8jikiLDmOv",
        "outputId": "26c9cb86-3ae1-4488-b781-e4170f5de7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35663 entries, 0 to 35662\n",
            "Columns: 136 entries, n_tokens_title to surprise2_optimism,sadness\n",
            "dtypes: float64(58), int64(78)\n",
            "memory usage: 37.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicción:"
      ],
      "metadata": {
        "id": "cGv4ncaHDuE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_preds = model.predict(x_test.values)\n",
        "proba_preds = model.predict_proba(x_test.values)[:, 1]"
      ],
      "metadata": {
        "id": "4YdV-DvXDxD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test.values, binary_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl66tB0_D0gi",
        "outputId": "c992f621-ec4a-47db-caef-4ac4661fd143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.80      0.99      0.89     28489\n",
            "        True       0.49      0.05      0.09      7174\n",
            "\n",
            "    accuracy                           0.80     35663\n",
            "   macro avg       0.65      0.52      0.49     35663\n",
            "weighted avg       0.74      0.80      0.73     35663\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_test.values, proba_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUVEybxDD3li",
        "outputId": "4f22e841-ce51-453d-bf4d-16f5806785c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6906041814660946"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El score obtenido para test fue 0.6906041814660946."
      ],
      "metadata": {
        "id": "S21TRWKfESIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardo las predicciones en un csv:"
      ],
      "metadata": {
        "id": "JZpl4kbrBeOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(proba_preds).to_csv(\"/content/drive/MyDrive/Datos/TP3/part2preds.csv\")"
      ],
      "metadata": {
        "id": "V5JGBGaZBeis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Features más importantes"
      ],
      "metadata": {
        "id": "W0U2Z1A65OVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coefs_index = (-np.absolute(model.best_estimator_.coef_[0])).argsort()[:10]\n",
        "coefs = []\n",
        "features = []\n",
        "for i in coefs_index:\n",
        "  coefs.append(model.best_estimator_.coef_[0][i])\n",
        "  features.append(x_train.columns[i])"
      ],
      "metadata": {
        "id": "vOl4aAU3EpNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los features más importantes para el modelo son:"
      ],
      "metadata": {
        "id": "4Q0dlV262st_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO0e52tX2ehu",
        "outputId": "484f1b83-23a0-4e90-86c5-f714ee58312d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['LDA_02', 'global_subjectivity', 'LDA_01', 'data_channel_is_bus', 'LDA_03', 'weekday_is_tuesday', 'min_positive_polarity', 'weekday_is_thursday', 'weekday_is_wednesday', 'LDA_04']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico"
      ],
      "metadata": {
        "id": "Z2C9tkr22zN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(dpi=125, figsize=(5,5))\n",
        "plt.bar(features, coefs, color='#f58802')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Peso')\n",
        "plt.title('Peso de los 10 features más importantes \\n para el modelo LogisticRegression')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylim(-0.8,0.8)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "hViIB1BMEtB2",
        "outputId": "7901d39e-ccea-4fe7-a97b-c7e5131ab5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 625x625 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se muestan los 10 features más importantes para el modelo con sus respectivos pesos. Un peso negativo indica que a medida que crece el feature la predicción tiende a ser 0, mientras que para uno positivo tiende a ser 1."
      ],
      "metadata": {
        "id": "17KNZsc_AKZL"
      }
    }
  ]
}